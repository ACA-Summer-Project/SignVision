{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "BNLFrMBIfBwJ",
        "outputId": "468fb3ac-b94e-4160-e531-68ef43493bbc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'species'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'species'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-298eef7b5508>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Encode target labels into integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'species'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'species'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# species → 0,1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Separate features and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'species'"
          ]
        }
      ],
      "source": [
        "# Step 1: Importing all necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Step 2: Load and preprocess the data\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/Iris.csv')\n",
        "\n",
        "# Encode target labels into integers\n",
        "label_encoder = LabelEncoder()\n",
        "df['species'] = label_encoder.fit_transform(df['species'])  # species → 0,1,2\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop('species', axis=1).values\n",
        "y = df['species'].values\n",
        "\n",
        "# Normalize feature values\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into 80% training and 20% test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test  = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Step 3: Data Visualization\n",
        "# Boxplots by species\n",
        "df_vis = pd.read_csv('iris.csv')\n",
        "plt.figure(figsize=(12, 8))\n",
        "for idx, column in enumerate(df_vis.columns[:-1]):\n",
        "    plt.subplot(2, 2, idx+1)\n",
        "    sns.boxplot(data=df_vis, x='species', y=column)\n",
        "    plt.title(f'Boxplot of {column} by species')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Optional: Pairplot\n",
        "sns.pairplot(df_vis, hue='species')\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Define the Neural Network Architecture\n",
        "class IrisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IrisNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 16)     # 4 features → 16 neurons\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(16, 3)     # 16 neurons → 3 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.fc1(x))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Instantiate the model\n",
        "model = IrisNet()\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Step 5: Train the model\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "# Number of epochs\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    # Forward pass and loss\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backpropagation and optimizer step\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Logging every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        # Evaluate on training data\n",
        "        train_pred = torch.argmax(model(X_train), dim=1)\n",
        "        train_acc = accuracy_score(y_train, train_pred)\n",
        "        train_loss = criterion(model(X_train), y_train).item()\n",
        "\n",
        "        # Evaluate on test data\n",
        "        test_pred = torch.argmax(model(X_test), dim=1)\n",
        "        test_acc = accuracy_score(y_test, test_pred)\n",
        "        test_loss = criterion(model(X_test), y_test).item()\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(test_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Test Loss={test_loss:.4f}, \"\n",
        "              f\"Train Acc={train_acc:.4f}, Test Acc={test_acc:.4f}\")\n",
        "\n",
        "# Step 6: Plotting Loss and Accuracy Graphs\n",
        "# Plot 1: Training and test loss vs. epochs\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(10, 101, 10), train_losses, label='Train Loss')\n",
        "plt.plot(range(10, 101, 10), test_losses, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epochs')\n",
        "plt.legend()\n",
        "\n",
        "# Plot 2: Training and test accuracy vs. epochs\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(10, 101, 10), train_accuracies, label='Train Accuracy')\n",
        "plt.plot(range(10, 101, 10), test_accuracies, label='Test Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs Epochs')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot 3: Confusion matrix\n",
        "final_preds = torch.argmax(model(X_test), dim=1)\n",
        "cm = confusion_matrix(y_test, final_preds)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d',\n",
        "            xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network with PyTorch — Classifying Iris Flowers\n",
        "Dataset: Iris Dataset (download the iris.csv)\n",
        "Objective: Build and train a neural network using PyTorch to classify iris flowers into\n",
        "one of three species.\n",
        "1. Load & Preprocess the Data\n",
        "o Load the dataset from the iris.csv file into a Pandas DataFrame.\n",
        "o Encode the target column (species) as integer labels (0, 1, 2).\n",
        "o Split the dataset into 80% training and 20% testing.\n",
        "o Normalize the feature values (e.g., using StandardScaler).\n",
        "2. Visualize the Data\n",
        "o Create box plots for each feature (sepal length, sepal width, petal length, petal\n",
        "width), separated by species to show the distribution and spread per class.\n",
        "o Optional: Create a pairplot (scatterplot matrix) of all features, colored by\n",
        "species.\n",
        "3. Build the Neural Network\n",
        "o Use PyTorch to define the following architecture:\n",
        "• Input layer: 4 neurons (one for each feature)\n",
        "• Hidden layer: 16 neurons with ReLU activation\n",
        "• Output layer: 3 neurons\n",
        "o Use CrossEntropyLoss as the loss function.\n",
        "o Use an optimizer such as SGD or Adam.\n",
        "4. Train the Model\n",
        "o Train the model for 100 epochs.\n",
        "o After every 10 epochs:\n",
        "• Calculate and print training and test loss.\n",
        "• Calculate and print training and test accuracy.\n",
        "5. Create the Following Plots\n",
        "o Plot 1: Training and test loss vs. epochs\n",
        "o Plot 2: Training and test accuracy vs. epochs\n",
        "o Plot 3: Final confusion matrix (visualized as a heatmap with class labels)"
      ],
      "metadata": {
        "id": "eyFTfv16h0rN"
      }
    }
  ]
}